{
 "metadata": {
  "name": "",
  "signature": "sha256:aba00b75da0bd62dc28de9dea323704ff9eefb4b1331db0487e3a23619149d23"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os, time, csv\n",
      "import psycopg2\n",
      "\n",
      "mypath = os.path.dirname(os.path.abspath(\"__file__\"))\n",
      "repositoryLocation = \"C:/git/SemanticTextDB\"\n",
      "sys.path.insert(0, os.path.normpath(os.path.join(mypath, 'C:/git/SemanticTextDB')))\n",
      "\n",
      "import SemanticTextDB as stdb\n",
      "\n",
      "conn = psycopg2.connect(database=\"benchmark\", user=\"Curtis Northcutt\", host=\"18.251.7.99\", password=\"coldnips\")\n",
      "cur = conn.cursor()\n",
      "\n",
      "# Now create a new SemanticTextDB object based on the underlying DB's state:\n",
      "my_stdb = stdb.SemanticTextDB(conn, cur)\n",
      "\n",
      "# PRINTS ALL TABLES IN DB:\n",
      "def allTables(cur):\n",
      "    cur.execute(\"select table_name from information_schema.tables WHERE table_schema='public' AND table_type='BASE TABLE';\")\n",
      "    return [x[0] for x in cur.fetchall()]\n",
      "\n",
      "# Shows at most 5 results from table:\n",
      "def seeTable(cur, name):\n",
      "    cur.execute(\"select * from \" + name + \";\")\n",
      "    x = cur.fetchall()\n",
      "    if len(x) < 5:\n",
      "        return x\n",
      "    else:\n",
      "        return x[:4]\n",
      "\n",
      "\n",
      "# Deletes all tables from DB:\t\n",
      "def clearDB(cur):\n",
      "    x = allTables(cur)\n",
      "    for t in x:\n",
      "        cur.execute(\"DROP TABLE \" + t + \";\")\n",
      "        cur.execute(\"COMMIT;\")\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Document tables in this database:  ['twitter']\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur.execute(\"END;\")\n",
      "cur.execute(\"ABORT;\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "import re\n",
      "readPath = \"C:/git/SemanticTextDB/example_code/all_US_Law_Codes/\"\n",
      "author = \"United States Government\"\n",
      "base_time = time.time()\n",
      "\n",
      "NUM_INTERTIMES = 10\n",
      "NUM_TRIALS = 5\n",
      "NUM_LAWS = 1001\n",
      "\n",
      "law_trials = []\n",
      "for i in range(NUM_TRIALS):\n",
      "    \n",
      "    clearDB(cur)\n",
      "\n",
      "    # Delete the document table (iff you want to replace table with same name):\n",
      "    if 'laws' in my_stdb.document_tables.keys(): #check that the table exists before deleting it\n",
      "        my_stdb.dropDocTable(\"laws\")\n",
      "\n",
      "    # Creates a document table (and associated machine-generated tables):\n",
      "    my_stdb.createDocTable(\"laws\", ['lawTitleNumber text', 'lawSectionNumber text', 'lawName text'],\n",
      "                       summary = None, topics = (10,20), entities = None, \n",
      "                       sentiment = False, count_words = False, length_count = False, \n",
      "                       vs_representations = None, max_word_length = 200,\n",
      "                       update_increment = 50, new_transaction = False)\n",
      "    \n",
      "    intertimes = []\n",
      "    count = 0\n",
      "    totaltime = 0\n",
      "    for filename in os.listdir(readPath):\n",
      "        count = count + 1\n",
      "        f = open(readPath + filename,'r')\n",
      "        fileAsString = f.read()\n",
      "        result = re.search(r'[0-9].*?\\n', fileAsString)\n",
      "        if result == None:\n",
      "            continue\n",
      "            #print fileAsString\n",
      "        else:\n",
      "            result = re.sub(r'\\n', '', result.group())\n",
      "            lawTitleNum = filename.split('_')[0]\n",
      "            lawSectionNum = (re.search(r'.*?\\.', result)).group()[:-1]\n",
      "            lawName = (re.search(r'\\..*', result)).group()[2:]\n",
      "\n",
      "            if lawName == \"\" or re.search(r'\\..*', result).group()[1] != \" \": #discard - wrong format\n",
      "                count = count - 1\n",
      "                continue\n",
      "            else:\n",
      "                #stringToInsert = unicode(fileAsString, 'utf-8')\n",
      "                fileAsString = re.sub(r'-', ' ', fileAsString)\n",
      "                fileAsString = re.sub(r'[^a-z ]', '', fileAsString)\n",
      "                fileAsString = re.sub(r' +', ' ', fileAsString)\n",
      "                \n",
      "                start_time = time.time()\n",
      "                my_stdb.insertDoc(fileAsString, \"laws\", [lawTitleNum, lawSectionNum, lawName])\n",
      "                totaltime = totaltime + (time.time() - start_time)\n",
      "                if count % (NUM_LAWS / NUM_INTERTIMES) == 0:\n",
      "                    print count\n",
      "                    intertimes.append(totaltime)\n",
      "        if count >= NUM_LAWS:\n",
      "            break\n",
      "    time_elapsed = time.time() - base_time\n",
      "    print 'Trial Completed:', i\n",
      "    print \"Estimated Minutes Left:\", (time_elapsed * NUM_TRIALS / (i + 1.0) - time_elapsed) / 60.0\n",
      "    print \"Time Elapsed:\", time_elapsed\n",
      "    law_trials.append(intertimes)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "created document table: laws\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "900"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trial Completed: 0\n",
        "Estimated Minutes Left: 3.5403333346\n",
        "Time Elapsed: 53.1050000191\n",
        "deleted document table: laws"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "created document table: laws"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-15-f25ba61cf77a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[1;31m#stringToInsert = unicode(fileAsString, 'utf-8')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mfileAsString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileAsString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mfileAsString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^a-z ]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileAsString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[0mfileAsString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr' +'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileAsString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\C\\Anaconda\\lib\\re.pyc\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\C\\Anaconda\\lib\\re.pyc\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(*key)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;31m# internal: compile pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[0mcachekey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcachekey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "with open(\"C:\\\\git\\\\SemanticTextDB\\\\example_code\\\\benchmark_results\\\\laws_1k_BATCH50_insert_lda.csv\", \"wb\") as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(law_trials)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def exception_proof_csv_reader(csv_reader):\n",
      "    '''Wraps a try-except clause around the csv reader to\n",
      "    prevent throwing of exceptions which will stop reading.'''\n",
      "    while True: \n",
      "      try: \n",
      "          yield next(csv_reader) \n",
      "      except csv.Error: \n",
      "          pass\n",
      "      continue "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cur.execute(\"END;\")\n",
      "cur.execute(\"ABORT;\")\n",
      "\n",
      "import re\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "twitterReadPath = \"C:/git/SemanticTextDB/example_code/twitter.csv\"\n",
      "base_time = time.time()\n",
      "\n",
      "NUM_INTERTIMES = 10\n",
      "NUM_TRIALS = 5\n",
      "NUM_TWEETS = 5001\n",
      "\n",
      "twitter_trials = []\n",
      "for i in range(NUM_TRIALS):\n",
      "    \n",
      "    clearDB(cur)\n",
      "    \n",
      "    # Delete the document table (iff you want to replace table with same name):\n",
      "    if 'twitter' in my_stdb.document_tables.keys(): #check that the table exists before deleting it\n",
      "        my_stdb.dropDocTable(\"twitter\")\n",
      "\n",
      "    # Creates a document table (and associated machine-generated tables):\n",
      "    my_stdb.createDocTable(\"twitter\", ['twitterId text', 'location text', 'username text'],\n",
      "                       summary = None, topics = (10,20), entities = None, \n",
      "                       sentiment = False, count_words = False, length_count = False, \n",
      "                       vs_representations = None, max_word_length = 200,\n",
      "                       update_increment = 10, new_transaction = False)\n",
      "    \n",
      "    intertimes = []\n",
      "    count = 0\n",
      "    totaltime = 0\n",
      "    with open(twitterReadPath, 'rU') as csvfile:\n",
      "        reader = exception_proof_csv_reader(csv.reader(csvfile, delimiter=','))\n",
      "        for row in reader:\n",
      "            count = count + 1\n",
      "            try:           \n",
      "                twitterID = row.pop(0)\n",
      "                location = row.pop(0)\n",
      "                username = row.pop(-1)\n",
      "                tweet = ', '.join(row)\n",
      "            except:\n",
      "                #print \"Error occurred at item\", count, \"skipping insertion.\"\n",
      "                count = count - 1\n",
      "                continue\n",
      "            \n",
      "            start_time = time.time()\n",
      "            \n",
      "            tweet = re.sub(r'-', ' ', tweet)\n",
      "            tweet = re.sub(r'[^a-z ]', '', tweet)\n",
      "            tweet = re.sub(r' +', ' ', tweet)\n",
      "\n",
      "            start_time = time.time()\n",
      "            my_stdb.insertDoc(tweet, \"twitter\", [twitterID, location, username])\n",
      "            \n",
      "            totaltime = totaltime + (time.time() - start_time)\n",
      "            \n",
      "            if count % (NUM_TWEETS / NUM_INTERTIMES) == 0:\n",
      "                intertimes.append(totaltime)                    \n",
      "                print count\n",
      "            if count >= NUM_TWEETS:\n",
      "                break\n",
      "    time_elapsed = time.time() - base_time\n",
      "    print 'Trial Completed:', i\n",
      "    print \"Estimated Minutes Left:\", (time_elapsed * NUM_TRIALS / (i + 1.0) - time_elapsed) / 60.0\n",
      "    print \"Time Elapsed:\", time_elapsed     \n",
      "    twitter_trials.append(intertimes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "deleted document table: twitter\n",
        "created document table: twitter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "InternalError",
       "evalue": "IndexError: pop index out of range\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"traintopicmodels\", line 101, in <module>\n    update_ids.pop(c)\nPL/Python function \"traintopicmodels\"\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-d2d08d2ee1a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mmy_stdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsertDoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"twitter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtwitterID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mtotaltime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotaltime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\git\\SemanticTextDB\\SemanticTextDB.pyc\u001b[0m in \u001b[0;36minsertDoc\u001b[1;34m(self, text, table_name, user_column_vals, id, new_transaction, persist_updates)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                 \u001b[1;31m# Check whether models should be updated and if so, perform the necessary updates:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_transaction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"COMMIT;\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\git\\SemanticTextDB\\SemanticTextDB.pyc\u001b[0m in \u001b[0;36mupdateModels\u001b[1;34m(self, doctable, last_text)\u001b[0m\n\u001b[0;32m    410\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtopics_on\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mupdate_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"countwords\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoctable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"traintopicmodels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoctable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# TODO: need methods for updating additional models.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mupdate_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mInternalError\u001b[0m: IndexError: pop index out of range\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"traintopicmodels\", line 101, in <module>\n    update_ids.pop(c)\nPL/Python function \"traintopicmodels\"\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "with open(\"C:\\\\git\\\\SemanticTextDB\\\\example_code\\\\benchmark_results\\\\twitter_5k_BATCH10_insert_lda.csv\", \"wb\") as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerows(twitter_trials)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}